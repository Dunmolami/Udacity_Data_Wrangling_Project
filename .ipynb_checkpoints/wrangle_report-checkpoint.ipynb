{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  wrangle_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Wrangling project was aimed at applying the knowledge of data wrangling gathered from the lessons. The data set wrangled was the tweet archive of @dog_rates A.K.A WeRateDogs. The twitter_archive_enhanced data, image prediction url and how to get twitter API was provided in the project description. The project was completed using jupyter notebook on machine with the classroom workspace template.\n",
    "The first step carried out was data gathering;\n",
    "1. The twitter_archive_enhanced.csv file was downloaded, then uploaded it into the Jupyter notebook and read into pandas DataFrame.\n",
    "2. The tweet_image prediction was downloaded programmatically using the request library with the url provided.\n",
    "3. The third dataset was gathered from Twitter API. To get Twitter API, I registered as twitter developer and created an app to get API keys, secrets and tokens which was used to create an API object. Each tweet ID was queried for each tweet's JSON data using Tweepy library and stored to a tweet_json.txt file with each tweet's JSON data on its own line. The JSON file was read line by line into a pandas DataFrame.\n",
    "\n",
    "The second step was data assessing. The three datasets named (df_dogs, df_predict and df_more_data) were assessed virtually and programmatically. In the process of assessment, 8 quality issues which had to do with the correctness of data, consistency of data etc. and 2 tidiness issues which have to do with the structure of the dataset were identified.\n",
    "\n",
    " The following Quality issues were identified;\n",
    " \n",
    " 1. The names of the dogs in P1, P2 and P3 are not consistent, some start with Capital letter and some with small letter in df_predict\n",
    "\n",
    "2. Expanded_urls has 59 missing values.There are lot of missing values in retweeted_status_user_id, retweeted_status_id, retweeted_status_timestamp, in_reply_to_status_id and in_reply_to_user_id in df_dogs\n",
    "\n",
    "3. Use of '_' instead of space in p1, p2 and p3\n",
    "\n",
    "\n",
    "4. Timestamp data type is object instead of datetime in df_dogs\n",
    "\n",
    "5.  tweet_id data type is integer instead of string in all the data\n",
    "\n",
    "6. Some names are not written correctly in df_dogs such as 'a', 'quite', etc.\n",
    "\n",
    "7. Missing values are represented differently, some as NaN and some as None\n",
    "\n",
    "8. Column names in df_predict are not descriptive\n",
    "\n",
    "The tidiness issues identified include:\n",
    "\n",
    "1. Merge clean_df_dogs table with clean_df_more_data.\n",
    "\n",
    "2. columns floofer, doggy, pupper and puppo in df_dogs shows different sizes of dogs, it should be merged into a column.\n",
    "\n",
    "After assessing the data, the next step was data cleaning. All the issues identified in data assessing step were cleaned using the define-code-test framework. For every issue cleaned, the process of cleaning was defined stating the steps to taken in cleaning the data and then the code to clean the dataset was written and then tested.\n",
    "\n",
    "The clean data was stored as csv file. The prediction data was stored separately as a csv file.\n",
    "\n",
    "The cleaned data was analysed and visualised.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
